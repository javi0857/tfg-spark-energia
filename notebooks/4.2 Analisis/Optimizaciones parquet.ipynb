{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4010ac-eb7a-4f29-84de-f10ca9df214f",
   "metadata": {},
   "source": [
    "# Analisis optimizaciones fichero .Parquet\n",
    "\n",
    "Para realizar el analisis, después de arrancar la sesión de Spark hay que ir ejecutando el codigo de las celdas y posteriormente meterse en el Spark UI para comparar los jobs ejecutados. Asi se puede observar las diferencias entre las consultas al fichero .csv y el .parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084e884b-7c36-4ae5-a662-c38f28c2fbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Loading <code>spark-stubs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://JAVITOP.mshome.net:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
       "\n",
       "\n",
       "//Iniciamos session de Spark\n",
       "\u001b[39m\r\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@1a099168\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.3`\n",
    "\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "\n",
    "\n",
    "//Reducir numero logs\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "\n",
    "//For adding extra dependenies\n",
    "import $ivy.`org.typelevel::cats-core:1.6.0`\n",
    "\n",
    "//Plotly\n",
    "import $ivy.`org.plotly-scala::plotly-almond:0.8.3`\n",
    "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
    "\n",
    "\n",
    "//Iniciamos session de Spark\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "     .master(\"local[*]\")\n",
    "    //.config(\"spark.executor.instances\", \"4\") // Número de ejecutores\n",
    "    //.config(\"spark.executor.memory\", \"4g\") // Memoria por ejecutor\n",
    "    //.config(\"spark.executor.cores\", \"2\") // Núcleos por ejecutor\n",
    "    //.config(\"spark.driver.memory\", \"4g\") // Memoria del driver\n",
    "    //.config(\"spark.sql.shuffle.partitions\", \"8\") // Número de particiones para operaciones de shuffle\n",
    "    .getOrCreate()\n",
    "}\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bb9c7-a31e-4025-936d-7b1b8d98edf3",
   "metadata": {},
   "source": [
    "#### Lectura simple de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df10d807-6137-4919-90fd-88749b116246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura CSV: 0.3589797 segundos\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura Parquet: 0.1673615 segundos\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [Familia#1635,Tipo#1636,Compuesto#1637,Porcentaje#1638,Valor#1639,Fecha#1640,BajasEmisiones#1641,Año#1642,Mes#1643] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/csv/dsBalanceNacionalAnalisis.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Familia:string,Tipo:string,Compuesto:boolean,Porcentaje:double,Valor:double,Fecha:timestam...\n",
      "== Physical Plan ==\n",
      "*(1) FileScan parquet [Familia#1653,Tipo#1654,Compuesto#1655,Porcentaje#1656,Valor#1657,Fecha#1658,BajasEmisiones#1659,Año#1660,Mes#1661] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/parquet/dsBalanceNacionalParticiona..., PartitionCount: 169, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Familia:string,Tipo:string,Compuesto:boolean,Porcentaje:double,Valor:double,Fecha:timestam...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpathCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/csv/dsBalanceNacionalAnalisis.csv\"\u001b[39m\r\n",
       "\u001b[36mpathParquet\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/parquet/dsBalanceNacionalParticionado.parquet\"\u001b[39m\r\n",
       "\u001b[36mstartCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783512048687500L\u001b[39m\r\n",
       "\u001b[36mdfFromCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Familia: string, Tipo: string ... 7 more fields]\r\n",
       "\u001b[36mendCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783512407667200L\u001b[39m\r\n",
       "\u001b[36mstartParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783512407933500L\u001b[39m\r\n",
       "\u001b[36mdfFromParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Familia: string, Tipo: string ... 7 more fields]\r\n",
       "\u001b[36mendParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783512575295000L\u001b[39m"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pathCsv = \"../../data/csv/dsBalanceNacionalAnalisis.csv\"      \n",
    "val pathParquet = \"../../data/parquet/dsBalanceNacionalParticionado.parquet\"\n",
    "\n",
    "// Medir tiempo de lectura CSV\n",
    "val startCsv = System.nanoTime()\n",
    "val dfFromCsv: DataFrame = spark.read\n",
    "    .option(\"header\", \"true\") // Para que Spark lea la primera linea como encabezado\n",
    "    .option(\"inferSchema\", \"true\") // Para inferir automáticamente el esquema\n",
    "    .csv(pathCsv)\n",
    "val endCsv = System.nanoTime()\n",
    "println(s\"Tiempo de lectura CSV: ${(endCsv - startCsv) / 1e9} segundos\")\n",
    "\n",
    "\n",
    "// Medir tiempo de lectura Parquet\n",
    "val startParquet = System.nanoTime()\n",
    "val dfFromParquet: DataFrame = spark.read.parquet(pathParquet)\n",
    "val endParquet = System.nanoTime()\n",
    "println(s\"Tiempo de lectura Parquet: ${(endParquet - startParquet) / 1e9} segundos\")\n",
    "\n",
    "// Ver esquema\n",
    "dfFromCsv.explain()\n",
    "dfFromParquet.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cd348-a64e-4ea4-84a7-7479e5e887b4",
   "metadata": {},
   "source": [
    "#### Lectura parcial (solo algunas columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46f623dd-d93c-46be-95d9-2390aa7e25e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [Fecha#425, Tipo#421, Valor#424]\n",
      "+- *(1) FileScan csv [Tipo#421,Valor#424,Fecha#425] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/csv/dsBalanceNacional11-25.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Tipo:string,Valor:double,Fecha:timestamp>\n",
      "== Physical Plan ==\n",
      "*(1) Project [Fecha#439, Tipo#435, Valor#438]\n",
      "+- *(1) FileScan parquet [Tipo#435,Valor#438,Fecha#439] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/parquet/dsBalanceNacional11-25.parq..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Tipo:string,Valor:double,Fecha:timestamp>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcolumnasFromCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Fecha: timestamp, Tipo: string ... 1 more field]\r\n",
       "\u001b[36mcolumnasFromParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Fecha: timestamp, Tipo: string ... 1 more field]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columnasFromCsv = dfFromCsv\n",
    "    .select(\"Fecha\", \"Tipo\", \"Valor\")\n",
    "\n",
    "columnasFromCsv.explain()\n",
    "\n",
    "val columnasFromParquet = dfFromParquet\n",
    "    .select(\"Fecha\", \"Tipo\", \"Valor\")\n",
    "\n",
    "columnasFromParquet.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6757d0-497e-42e4-a261-893bbc96d79e",
   "metadata": {},
   "source": [
    "#### Lectura filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "946473f7-7372-43c5-b938-7b5fae2950a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura CSV: 0.3754405 segundos\n",
      "== Physical Plan ==\n",
      "*(1) Project [Familia#1801, Tipo#1802, Compuesto#1803, Porcentaje#1804, Valor#1805, Fecha#1806, BajasEmisiones#1807, Año#1808, Mes#1809]\n",
      "+- *(1) Filter (((isnotnull(Año#1808) && isnotnull(Mes#1809)) && (Año#1808 = 2024)) && (Mes#1809 = 1))\n",
      "   +- *(1) FileScan csv [Familia#1801,Tipo#1802,Compuesto#1803,Porcentaje#1804,Valor#1805,Fecha#1806,BajasEmisiones#1807,Año#1808,Mes#1809] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/csv/dsBalanceNacionalAnalisis.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Año), IsNotNull(Mes), EqualTo(Año,2024), EqualTo(Mes,1)], ReadSchema: struct<Familia:string,Tipo:string,Compuesto:boolean,Porcentaje:double,Valor:double,Fecha:timestam...\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "|  Familia|      Tipo|Compuesto|         Porcentaje|    Valor|              Fecha|BajasEmisiones| Año|Mes|\n",
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "|Renovable|Hidráulica|    false|0.19718853720380722|58381.148|2024-01-01 01:00:00|          true|2024|  1|\n",
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpathCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/csv/dsBalanceNacionalAnalisis.csv\"\u001b[39m\r\n",
       "\u001b[36mpathParquet\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/parquet/dsBalanceNacionalParticionado.parquet\"\u001b[39m\r\n",
       "\u001b[36mstartCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m784023217208500L\u001b[39m\r\n",
       "\u001b[36mdfCsvFiltered\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Familia: string, Tipo: string ... 7 more fields]\r\n",
       "\u001b[36mendCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m784023592649000L\u001b[39m"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pathCsv = \"../../data/csv/dsBalanceNacionalAnalisis.csv\"      \n",
    "val pathParquet = \"../../data/parquet/dsBalanceNacionalParticionado.parquet\"\n",
    "\n",
    "//csv\n",
    "val startCsv = System.nanoTime()\n",
    "val dfCsvFiltered = spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(pathCsv)\n",
    "    .filter($\"Año\" === 2024 && $\"Mes\" === 1)// Filtro directo en la columna sin transformaciones\n",
    "\n",
    "val endCsv = System.nanoTime()\n",
    "\n",
    "println(s\"Tiempo de lectura CSV: ${(endCsv - startCsv) / 1e9} segundos\")\n",
    "\n",
    "dfCsvFiltered.explain() // Ver plan de ejecución\n",
    "dfCsvFiltered.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "304639cc-3d88-45ed-8959-7b438e8b5c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura Parquet: 0.2106526 segundos\n",
      "== Physical Plan ==\n",
      "*(1) FileScan parquet [Familia#1578,Tipo#1579,Compuesto#1580,Porcentaje#1581,Valor#1582,Fecha#1583,BajasEmisiones#1584,Año#1585,Mes#1586] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/parquet/dsBalanceNacionalParticiona..., PartitionCount: 1, PartitionFilters: [isnotnull(Año#1585), isnotnull(Mes#1586), (Año#1585 = 2024), (Mes#1586 = 1)], PushedFilters: [], ReadSchema: struct<Familia:string,Tipo:string,Compuesto:boolean,Porcentaje:double,Valor:double,Fecha:timestam...\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "|  Familia|      Tipo|Compuesto|         Porcentaje|    Valor|              Fecha|BajasEmisiones| Año|Mes|\n",
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "|Renovable|Hidráulica|    false|0.19718853720380722|58381.148|2024-01-01 01:00:00|          true|2024|  1|\n",
      "+---------+----------+---------+-------------------+---------+-------------------+--------------+----+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mstartParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783399512523100L\u001b[39m\r\n",
       "\u001b[36mdfParquetFiltered\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Familia: string, Tipo: string ... 7 more fields]\r\n",
       "\u001b[36mendParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m783399723175700L\u001b[39m"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Parquet\n",
    "val startParquet = System.nanoTime()\n",
    "\n",
    "val dfParquetFiltered = spark.read\n",
    "    .parquet(pathParquet)\n",
    "    .filter($\"Año\" === 2024 && $\"Mes\" === 1) // Filtro directo en la columna sin transformaciones\n",
    "\n",
    "val endParquet = System.nanoTime()\n",
    "\n",
    "println(s\"Tiempo de lectura Parquet: ${(endParquet - startParquet) / 1e9} segundos\")\n",
    "\n",
    "dfParquetFiltered.explain() // Ver plan de ejecución\n",
    "dfParquetFiltered.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa0317-7440-4097-9132-759e7c984748",
   "metadata": {},
   "source": [
    "#### Agrupaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5c95522-1c37-43db-84b2-656d3da0f146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura CSV: 0.4236098 segundos\n",
      "== Parsed Logical Plan ==\n",
      "'Aggregate [Tipo#1868], [Tipo#1868, sum('Valor) AS TotalGenerado#1895, avg('Porcentaje) AS PorcentajePromedio#1897]\n",
      "+- Filter (Familia#1867 = Renovable)\n",
      "   +- Filter ((Año#1874 = 2024) && (Mes#1875 = 1))\n",
      "      +- Relation[Familia#1867,Tipo#1868,Compuesto#1869,Porcentaje#1870,Valor#1871,Fecha#1872,BajasEmisiones#1873,Año#1874,Mes#1875] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Tipo: string, TotalGenerado: double, PorcentajePromedio: double\n",
      "Aggregate [Tipo#1868], [Tipo#1868, sum(Valor#1871) AS TotalGenerado#1895, avg(Porcentaje#1870) AS PorcentajePromedio#1897]\n",
      "+- Filter (Familia#1867 = Renovable)\n",
      "   +- Filter ((Año#1874 = 2024) && (Mes#1875 = 1))\n",
      "      +- Relation[Familia#1867,Tipo#1868,Compuesto#1869,Porcentaje#1870,Valor#1871,Fecha#1872,BajasEmisiones#1873,Año#1874,Mes#1875] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [Tipo#1868], [Tipo#1868, sum(Valor#1871) AS TotalGenerado#1895, avg(Porcentaje#1870) AS PorcentajePromedio#1897]\n",
      "+- Project [Tipo#1868, Porcentaje#1870, Valor#1871]\n",
      "   +- Filter (((((isnotnull(Mes#1875) && isnotnull(Familia#1867)) && isnotnull(Año#1874)) && (Año#1874 = 2024)) && (Mes#1875 = 1)) && (Familia#1867 = Renovable))\n",
      "      +- Relation[Familia#1867,Tipo#1868,Compuesto#1869,Porcentaje#1870,Valor#1871,Fecha#1872,BajasEmisiones#1873,Año#1874,Mes#1875] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Tipo#1868], functions=[sum(Valor#1871), avg(Porcentaje#1870)], output=[Tipo#1868, TotalGenerado#1895, PorcentajePromedio#1897])\n",
      "+- Exchange hashpartitioning(Tipo#1868, 200)\n",
      "   +- *(1) HashAggregate(keys=[Tipo#1868], functions=[partial_sum(Valor#1871), partial_avg(Porcentaje#1870)], output=[Tipo#1868, sum#1905, sum#1906, count#1907L])\n",
      "      +- *(1) Project [Tipo#1868, Porcentaje#1870, Valor#1871]\n",
      "         +- *(1) Filter (((((isnotnull(Mes#1875) && isnotnull(Familia#1867)) && isnotnull(Año#1874)) && (Año#1874 = 2024)) && (Mes#1875 = 1)) && (Familia#1867 = Renovable))\n",
      "            +- *(1) FileScan csv [Familia#1867,Tipo#1868,Porcentaje#1870,Valor#1871,Año#1874,Mes#1875] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/csv/dsBalanceNacionalAnalisis.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Mes), IsNotNull(Familia), IsNotNull(Año), EqualTo(Año,2024), EqualTo(Mes,1), EqualTo(F..., ReadSchema: struct<Familia:string,Tipo:string,Porcentaje:double,Valor:double,Año:int,Mes:int>\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+--------------------+\n",
      "|               Tipo|     TotalGenerado|  PorcentajePromedio|\n",
      "+-------------------+------------------+--------------------+\n",
      "|Residuos renovables| 69243.12599999999|0.005950484155910...|\n",
      "| Solar fotovoltaica|1932458.7750000001| 0.16709750936029064|\n",
      "|      Solar térmica| 94242.96699999998|0.008281224136326733|\n",
      "|   Otras renovables| 283523.7090000001| 0.02439302139040502|\n",
      "|        Hidroeólica| 739.2880000000001|6.366359586924555E-5|\n",
      "+-------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mstartCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m785003079486700L\u001b[39m\r\n",
       "\u001b[36mdfCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Tipo: string, TotalGenerado: double ... 1 more field]\r\n",
       "\u001b[36mendCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m785003503096500L\u001b[39m"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val startCsv = System.nanoTime()\n",
    "\n",
    "val dfCsv = spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\") // Spark debe inferir el esquema en cada lectura\n",
    "    .csv(pathCsv)\n",
    "    .filter($\"Año\" === 2024 && $\"Mes\" === 1) // NO optimizado (lee todo el archivo)\n",
    "    .filter($\"Familia\" === \"Renovable\") // NO optimizado (lee todas las filas)\n",
    "    .groupBy(\"Tipo\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"TotalGenerado\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajePromedio\")\n",
    "    )\n",
    "\n",
    "val endCsv = System.nanoTime()\n",
    "println(s\"Tiempo de lectura CSV: ${(endCsv - startCsv) / 1e9} segundos\")\n",
    "\n",
    "dfCsv.explain(true)\n",
    "dfCsv.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecbe9371-e091-4ea0-b99e-12a9a0a9d469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de lectura Parquet: 0.2106089 segundos\n",
      "== Parsed Logical Plan ==\n",
      "'Aggregate [Tipo#1931], [Tipo#1931, sum('Valor) AS TotalGenerado#1958, avg('Porcentaje) AS PorcentajePromedio#1960]\n",
      "+- Filter (Familia#1930 = Renovable)\n",
      "   +- Filter ((Año#1937 = 2024) && (Mes#1938 = 1))\n",
      "      +- Relation[Familia#1930,Tipo#1931,Compuesto#1932,Porcentaje#1933,Valor#1934,Fecha#1935,BajasEmisiones#1936,Año#1937,Mes#1938] parquet\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Tipo: string, TotalGenerado: double, PorcentajePromedio: double\n",
      "Aggregate [Tipo#1931], [Tipo#1931, sum(Valor#1934) AS TotalGenerado#1958, avg(Porcentaje#1933) AS PorcentajePromedio#1960]\n",
      "+- Filter (Familia#1930 = Renovable)\n",
      "   +- Filter ((Año#1937 = 2024) && (Mes#1938 = 1))\n",
      "      +- Relation[Familia#1930,Tipo#1931,Compuesto#1932,Porcentaje#1933,Valor#1934,Fecha#1935,BajasEmisiones#1936,Año#1937,Mes#1938] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [Tipo#1931], [Tipo#1931, sum(Valor#1934) AS TotalGenerado#1958, avg(Porcentaje#1933) AS PorcentajePromedio#1960]\n",
      "+- Project [Tipo#1931, Porcentaje#1933, Valor#1934]\n",
      "   +- Filter (((((isnotnull(Año#1937) && isnotnull(Familia#1930)) && isnotnull(Mes#1938)) && (Año#1937 = 2024)) && (Mes#1938 = 1)) && (Familia#1930 = Renovable))\n",
      "      +- Relation[Familia#1930,Tipo#1931,Compuesto#1932,Porcentaje#1933,Valor#1934,Fecha#1935,BajasEmisiones#1936,Año#1937,Mes#1938] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Tipo#1931], functions=[sum(Valor#1934), avg(Porcentaje#1933)], output=[Tipo#1931, TotalGenerado#1958, PorcentajePromedio#1960])\n",
      "+- Exchange hashpartitioning(Tipo#1931, 200)\n",
      "   +- *(1) HashAggregate(keys=[Tipo#1931], functions=[partial_sum(Valor#1934), partial_avg(Porcentaje#1933)], output=[Tipo#1931, sum#1968, sum#1969, count#1970L])\n",
      "      +- *(1) Project [Tipo#1931, Porcentaje#1933, Valor#1934]\n",
      "         +- *(1) Filter (isnotnull(Familia#1930) && (Familia#1930 = Renovable))\n",
      "            +- *(1) FileScan parquet [Familia#1930,Tipo#1931,Porcentaje#1933,Valor#1934,Año#1937,Mes#1938] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/C:/Proyectos/spark-datos-energia/data/parquet/dsBalanceNacionalParticiona..., PartitionCount: 1, PartitionFilters: [isnotnull(Año#1937), isnotnull(Mes#1938), (Año#1937 = 2024), (Mes#1938 = 1)], PushedFilters: [IsNotNull(Familia), EqualTo(Familia,Renovable)], ReadSchema: struct<Familia:string,Tipo:string,Porcentaje:double,Valor:double>\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+--------------------+\n",
      "|               Tipo|     TotalGenerado|  PorcentajePromedio|\n",
      "+-------------------+------------------+--------------------+\n",
      "|Residuos renovables| 69243.12599999999|0.005950484155910...|\n",
      "| Solar fotovoltaica|1932458.7750000001| 0.16709750936029064|\n",
      "|      Solar térmica| 94242.96699999998|0.008281224136326733|\n",
      "|   Otras renovables| 283523.7090000001| 0.02439302139040502|\n",
      "|        Hidroeólica| 739.2880000000001|6.366359586924555E-5|\n",
      "+-------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mstartParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m785067117229600L\u001b[39m\r\n",
       "\u001b[36mdfParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Tipo: string, TotalGenerado: double ... 1 more field]\r\n",
       "\u001b[36mendParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m785067327838500L\u001b[39m"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Parquet\n",
    "val startParquet = System.nanoTime()\n",
    "\n",
    "val dfParquet = spark.read\n",
    "    .parquet(pathParquet)\n",
    "    .filter($\"Año\" === 2024 && $\"Mes\" === 1) // Partition Pruning (lee solo las carpetas necesarias)\n",
    "    .filter($\"Familia\" === \"Renovable\") // Predicate Pushdown (lee solo las filas necesarias)\n",
    "    .groupBy(\"Tipo\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"TotalGenerado\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajePromedio\")\n",
    "    )\n",
    "val endParquet = System.nanoTime()\n",
    "\n",
    "println(s\"Tiempo de lectura Parquet: ${(endParquet - startParquet) / 1e9} segundos\")\n",
    "\n",
    "\n",
    "dfParquet.explain(true)\n",
    "dfParquet.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5e5866c-00d2-46b5-8cfc-d73f88178489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Tipo|count|\n",
      "+--------------------+-----+\n",
      "| Residuos renovables| 5145|\n",
      "|     Demanda en b.c.| 5145|\n",
      "|  Turbinación bombeo| 5145|\n",
      "|Saldo almacenamiento| 5145|\n",
      "|     Consumos bombeo| 5145|\n",
      "|  Solar fotovoltaica| 5145|\n",
      "|       Solar térmica| 5141|\n",
      "|Generación no ren...| 5145|\n",
      "|    Otras renovables| 5145|\n",
      "|             Nuclear| 5145|\n",
      "|         Hidroeólica| 3838|\n",
      "|      Turbina de gas| 5145|\n",
      "|Generación renovable| 5145|\n",
      "|Residuos no renov...| 5145|\n",
      "|        Cogeneración| 5145|\n",
      "|Saldo I. internac...| 5145|\n",
      "|       Carga batería|  727|\n",
      "|     Entrega batería|  665|\n",
      "|      Motores diésel| 5145|\n",
      "|              Eólica| 5145|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromParquet.groupBy(\"Tipo\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f48eee0-26b6-44ca-882a-16d604ef4af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "| Año|     Familia|                Tipo|Compuesto|BajasEmisiones|         ValorAnual|PorcentajeAnualSobreFamilia| TotalGenerado|PorcentajeSobreTotal|PorcentajeBajasEmisiones|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "|2016|No-Renovable|    Turbina de vapor|    false|         false| 2536143.0030000005|         0.0167077641039327|2.5700810617E8|                0.99|                   61.13|\n",
      "|2016|No-Renovable|      Turbina de gas|    false|         false|  616037.3019999998|       0.003893066689377...|2.5700810617E8|                0.24|                   61.13|\n",
      "|2016|   Renovable|       Solar térmica|    false|          true|  5071201.701999999|       0.054412720483706205|2.5700810617E8|                1.97|                   61.13|\n",
      "|2016|No-Renovable|Generación no ren...|     true|         false|1.576121932575001E8|                        1.0|2.5700810617E8|               61.33|                   61.13|\n",
      "|2016|   Renovable|          Hidráulica|    false|          true|3.611488819499998E7|         0.3577566818747559|2.5700810617E8|               14.05|                   61.13|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Tiempo ejecución Parquet: 0.6790475 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mstartParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m704686483035900L\u001b[39m\r\n",
       "\u001b[36mventanaParquet\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@52c3df61\r\n",
       "\u001b[36mdatosBalanceAnualesParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Año: string, Familia: string ... 8 more fields]\r\n",
       "\u001b[36mendParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m704687162083400L\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//parquet\n",
    "\n",
    "val startParquet = System.nanoTime()\n",
    "val ventanaParquet = Window.partitionBy(\"Año\")\n",
    "\n",
    "val datosBalanceAnualesParquet = dfFromParquet\n",
    "    .withColumn(\"Año\", date_format($\"Fecha\", \"yyyy\"))\n",
    "    .groupBy($\"Año\", $\"Familia\", $\"Tipo\", $\"Compuesto\", $\"BajasEmisiones\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"ValorAnual\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajeAnualSobreFamilia\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"TotalGenerado\", \n",
    "        round(\n",
    "            sum(\n",
    "                when(!$\"Compuesto\" && $\"Familia\" =!= \"Demanda\" ,$\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaParquet),2)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"PorcentajeSobreTotal\", \n",
    "        round($\"ValorAnual\" / $\"TotalGenerado\" * 100,2))\n",
    "    .withColumn(\n",
    "        \"PorcentajeBajasEmisiones\", \n",
    "        round(\n",
    "            sum(\n",
    "                when($\"BajasEmisiones\" && !$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaParquet) / $\"TotalGenerado\" * 100,2)\n",
    "    )\n",
    "\n",
    "// Mostrar los primeros resultados y explicar el plan de ejecución\n",
    "datosBalanceAnualesParquet.show(5)\n",
    "//datosBalanceAnualesParquet.explain(true)\n",
    "val endParquet = System.nanoTime()\n",
    "println(s\"Tiempo ejecución Parquet: ${(endParquet - startParquet) / 1e9} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ad4f9e-8f94-4b69-8667-0c494527a7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "| Año|     Familia|                Tipo|Compuesto|BajasEmisiones|         ValorAnual|PorcentajeAnualSobreFamilia| TotalGenerado|PorcentajeSobreTotal|PorcentajeBajasEmisiones|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "|2016|No-Renovable|    Turbina de vapor|    false|         false| 2536143.0030000005|         0.0167077641039327|2.5700810617E8|                0.99|                   61.13|\n",
      "|2016|No-Renovable|      Turbina de gas|    false|         false|  616037.3019999998|       0.003893066689377...|2.5700810617E8|                0.24|                   61.13|\n",
      "|2016|   Renovable|       Solar térmica|    false|          true|  5071201.701999999|       0.054412720483706205|2.5700810617E8|                1.97|                   61.13|\n",
      "|2016|No-Renovable|Generación no ren...|     true|         false|1.576121932575001E8|                        1.0|2.5700810617E8|               61.33|                   61.13|\n",
      "|2016|   Renovable|          Hidráulica|    false|          true|3.611488819499998E7|         0.3577566818747559|2.5700810617E8|               14.05|                   61.13|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Tiempo ejecución CSV: 0.812591 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mstartCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m704682062526900L\u001b[39m\r\n",
       "\u001b[36mventanaCsv\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@503e0a9d\r\n",
       "\u001b[36mdatosBalanceAnualesCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Año: string, Familia: string ... 8 more fields]\r\n",
       "\u001b[36mendCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m704682875117900L\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//csv\n",
    "val startCsv = System.nanoTime()\n",
    "\n",
    "val ventanaCsv = Window.partitionBy(\"Año\")\n",
    "val datosBalanceAnualesCsv = dfFromCsv\n",
    "    .withColumn(\"Año\", date_format($\"Fecha\", \"yyyy\"))\n",
    "    .groupBy($\"Año\", $\"Familia\", $\"Tipo\", $\"Compuesto\", $\"BajasEmisiones\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"ValorAnual\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajeAnualSobreFamilia\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"TotalGenerado\", \n",
    "        round(\n",
    "            sum(\n",
    "                when(!$\"Compuesto\" && $\"Familia\" =!= \"Demanda\" ,$\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaCsv),2)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"PorcentajeSobreTotal\", \n",
    "        round($\"ValorAnual\" / $\"TotalGenerado\" * 100,2))\n",
    "    .withColumn(\n",
    "        \"PorcentajeBajasEmisiones\", \n",
    "        round(\n",
    "            sum(\n",
    "                when($\"BajasEmisiones\" && !$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaCsv) / $\"TotalGenerado\" * 100,2)\n",
    "    )\n",
    "\n",
    "// Mostrar los primeros resultados y explicar el plan de ejecución\n",
    "datosBalanceAnualesCsv.show(5)\n",
    "//datosBalanceAnualesCsv.explain(true)\n",
    "\n",
    "val endCsv = System.nanoTime()\n",
    "println(s\"Tiempo ejecución CSV: ${(endCsv - startCsv) / 1e9} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d6d9c23-e27b-47af-9086-8a8b34791d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "| Año|     Familia|                Tipo|Compuesto|BajasEmisiones|         ValorAnual|PorcentajeAnualSobreFamilia| TotalGenerado|PorcentajeSobreTotal|PorcentajeBajasEmisiones|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "|2016|No-Renovable|    Turbina de vapor|    false|         false| 2536143.0030000005|         0.0167077641039327|2.5700810617E8|                0.99|                   61.13|\n",
      "|2016|No-Renovable|      Turbina de gas|    false|         false|  616037.3019999998|       0.003893066689377...|2.5700810617E8|                0.24|                   61.13|\n",
      "|2016|   Renovable|       Solar térmica|    false|          true|  5071201.701999999|       0.054412720483706205|2.5700810617E8|                1.97|                   61.13|\n",
      "|2016|No-Renovable|Generación no ren...|     true|         false|1.576121932575001E8|                        1.0|2.5700810617E8|               61.33|                   61.13|\n",
      "|2016|   Renovable|          Hidráulica|    false|          true|3.611488819499998E7|         0.3577566818747559|2.5700810617E8|               14.05|                   61.13|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Tiempo ejecución CSV: 1.1499216 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\r\n",
       "\u001b[36mpathCsv\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/csv/dsBalanceNacional11-25.csv\"\u001b[39m\r\n",
       "\u001b[36mstartCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m705252237406700L\u001b[39m\r\n",
       "\u001b[36mdfFromCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Familia: string, Tipo: string ... 5 more fields]\r\n",
       "\u001b[36mventanaCsv\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@6959bb9e\r\n",
       "\u001b[36mdatosBalanceAnualesCsv\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Año: string, Familia: string ... 8 more fields]\r\n",
       "\u001b[36mendCsv\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m705253387328300L\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// 📌 Leer datos desde CSV con inferSchema activado\n",
    "val pathCsv = \"../../data/csv/dsBalanceNacional11-25.csv\"\n",
    "\n",
    "val startCsv = System.nanoTime()\n",
    "\n",
    "val dfFromCsv = spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\") // Spark inferirá automáticamente los tipos de datos\n",
    "    .csv(pathCsv)\n",
    "\n",
    "val ventanaCsv = Window.partitionBy(\"Año\")\n",
    "\n",
    "val datosBalanceAnualesCsv = dfFromCsv\n",
    "    .withColumn(\"Año\", date_format($\"Fecha\", \"yyyy\"))\n",
    "    .groupBy($\"Año\", $\"Familia\", $\"Tipo\", $\"Compuesto\", $\"BajasEmisiones\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"ValorAnual\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajeAnualSobreFamilia\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"TotalGenerado\", \n",
    "        round(\n",
    "            sum(\n",
    "                when(!$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaCsv),2)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"PorcentajeSobreTotal\", \n",
    "        round($\"ValorAnual\" / $\"TotalGenerado\" * 100,2))\n",
    "    .withColumn(\n",
    "        \"PorcentajeBajasEmisiones\", \n",
    "        round(\n",
    "            sum(\n",
    "                when($\"BajasEmisiones\" && !$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaCsv) / $\"TotalGenerado\" * 100,2)\n",
    "    )\n",
    "\n",
    "// Mostrar resultados y calcular tiempo de ejecución\n",
    "datosBalanceAnualesCsv.show(5)\n",
    "\n",
    "val endCsv = System.nanoTime()\n",
    "println(s\"Tiempo ejecución CSV: ${(endCsv - startCsv) / 1e9} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab644ba-64b3-4e02-b0ac-29e59a3c8953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "| Año|     Familia|                Tipo|Compuesto|BajasEmisiones|         ValorAnual|PorcentajeAnualSobreFamilia| TotalGenerado|PorcentajeSobreTotal|PorcentajeBajasEmisiones|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "|2016|No-Renovable|    Turbina de vapor|    false|         false| 2536143.0030000005|         0.0167077641039327|2.5700810617E8|                0.99|                   61.13|\n",
      "|2016|No-Renovable|      Turbina de gas|    false|         false|  616037.3019999998|       0.003893066689377...|2.5700810617E8|                0.24|                   61.13|\n",
      "|2016|   Renovable|       Solar térmica|    false|          true|  5071201.701999999|       0.054412720483706205|2.5700810617E8|                1.97|                   61.13|\n",
      "|2016|No-Renovable|Generación no ren...|     true|         false|1.576121932575001E8|                        1.0|2.5700810617E8|               61.33|                   61.13|\n",
      "|2016|   Renovable|          Hidráulica|    false|          true|3.611488819499998E7|         0.3577566818747559|2.5700810617E8|               14.05|                   61.13|\n",
      "+----+------------+--------------------+---------+--------------+-------------------+---------------------------+--------------+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Tiempo ejecución Parquet: 0.8068491 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\r\n",
       "\u001b[36mpathParquet\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../data/parquet/dsBalanceNacional11-25.parquet\"\u001b[39m\r\n",
       "\u001b[36mstartParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m705273071622100L\u001b[39m\r\n",
       "\u001b[36mdfFromParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Familia: string, Tipo: string ... 5 more fields]\r\n",
       "\u001b[36mventanaParquet\u001b[39m: \u001b[32mexpressions\u001b[39m.\u001b[32mWindowSpec\u001b[39m = org.apache.spark.sql.expressions.WindowSpec@3c562df2\r\n",
       "\u001b[36mdatosBalanceAnualesParquet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Año: string, Familia: string ... 8 more fields]\r\n",
       "\u001b[36mendParquet\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m705273878471200L\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// 📌 Leer datos desde Parquet\n",
    "val pathParquet = \"../../data/parquet/dsBalanceNacional11-25.parquet\"\n",
    "\n",
    "val startParquet = System.nanoTime()\n",
    "\n",
    "val dfFromParquet = spark.read\n",
    "    .parquet(pathParquet)\n",
    "\n",
    "val ventanaParquet = Window.partitionBy(\"Año\")\n",
    "\n",
    "val datosBalanceAnualesParquet = dfFromParquet\n",
    "    .withColumn(\"Año\", date_format($\"Fecha\", \"yyyy\"))\n",
    "    .groupBy($\"Año\", $\"Familia\", $\"Tipo\", $\"Compuesto\", $\"BajasEmisiones\")\n",
    "    .agg(\n",
    "        sum(\"Valor\").as(\"ValorAnual\"),\n",
    "        avg(\"Porcentaje\").as(\"PorcentajeAnualSobreFamilia\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"TotalGenerado\", \n",
    "        round(\n",
    "            sum(\n",
    "                when(!$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaParquet),2)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"PorcentajeSobreTotal\", \n",
    "        round($\"ValorAnual\" / $\"TotalGenerado\" * 100,2))\n",
    "    .withColumn(\n",
    "        \"PorcentajeBajasEmisiones\", \n",
    "        round(\n",
    "            sum(\n",
    "                when($\"BajasEmisiones\" && !$\"Compuesto\" && $\"Familia\" =!= \"Demanda\", $\"ValorAnual\")\n",
    "                    .otherwise(0)).over(ventanaParquet) / $\"TotalGenerado\" * 100,2)\n",
    "    )\n",
    "\n",
    "// Mostrar resultados y calcular tiempo de ejecución\n",
    "datosBalanceAnualesParquet.show(5)\n",
    "\n",
    "val endParquet = System.nanoTime()\n",
    "println(s\"Tiempo ejecución Parquet: ${(endParquet - startParquet) / 1e9} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a35eb-cd9b-4b51-bb10-64ac5a2daaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
